from langchain.tools import tool
from langchain_openai import ChatOpenAI
openai_api_key="sk-nRyX1HmENCf4QEk5V0yWZKrQkIKKnEfXloy9lSOe3Jjl9AJH"
base_url="https://api.poixe.com/v1"

model = ChatOpenAI(
    openai_api_key=openai_api_key,
    base_url=base_url
)

# Define tools
@tool
def multiply(a: int, b: int) -> int:
    """Multiply `a` and `b`.

    Args:
        a: First int
        b: Second int
    """
    return a * b


@tool
def add(a: int, b: int) -> int:
    """Adds `a` and `b`.

    Args:
        a: First int
        b: Second int
    """
    return a + b


@tool
def divide(a: int, b: int) -> float:
    """Divide `a` and `b`.

    Args:
        a: First int
        b: Second int
    """
    return a / b


# Augment the LLM with tools
tools = [add, multiply, divide]
tools_by_name = {tool.name: tool for tool in tools}
model_with_tools = model.bind_tools(tools)


from langchain.messages import AnyMessage
from typing_extensions import TypedDict, Annotated
import operator


class MessagesState(TypedDict):
    messages: Annotated[list[AnyMessage], operator.add]
    llm_calls: int

from langchain.messages import SystemMessage
from langgraph.store.base import BaseStore
from langchain_core.runnables import RunnableConfig


def llm_call(state: dict, config: RunnableConfig, *, store: BaseStore):
    """LLM decides whether to call a tool or not

    store å‚æ•°ä¼šè¢« LangGraph è‡ªåŠ¨æ³¨å…¥ï¼
    """

    # ä» config ä¸­è·å– user_idï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    user_id = config.get("configurable", {}).get("user_id", "default_user")

    # è‡ªåŠ¨ä» store è¯»å–ç”¨æˆ·åå¥½
    prefs = store.get(namespace=("users", user_id), key="preferences")
    if prefs:
        print(f"   ğŸ“¦ [Store] è¯»å–åˆ°ç”¨æˆ·åå¥½: {prefs.value}")

    result = model_with_tools.invoke(
        [
            SystemMessage(
                content="You are a helpful assistant tasked with performing arithmetic on a set of inputs."
            )
        ]
        + state["messages"]
    )

    # è‡ªåŠ¨ä¿å­˜è®¡ç®—å†å²åˆ° store
    call_count = state.get('llm_calls', 0) + 1
    store.put(
        namespace=("history", user_id),
        key=f"call_{call_count}",
        value={
            "call_number": call_count,
            "input": state["messages"][-1].content if state["messages"] else "",
            "has_tool_call": bool(result.tool_calls)
        }
    )
    print(f"   ğŸ“¦ [Store] è‡ªåŠ¨ä¿å­˜è°ƒç”¨å†å²: call_{call_count}")

    return {
        "messages": [result],
        "llm_calls": call_count
    }

from langchain.messages import ToolMessage

def tool_node(state: dict):
    """Performs the tool call"""

    result = []
    for tool_call in state["messages"][-1].tool_calls:
        tool = tools_by_name[tool_call["name"]]
        observation = tool.invoke(tool_call["args"])
        result.append(ToolMessage(content=observation, tool_call_id=tool_call["id"]))
    return {"messages": result}

from typing import Literal
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.store.memory import InMemoryStore
from langgraph.types import interrupt, Command

def should_continue(state: MessagesState) -> Literal["tool_node", END]:
    """Decide if we should continue the loop or stop based upon whether the LLM made a tool call"""

    messages = state["messages"]
    last_message = messages[-1]

    # If the LLM makes a tool call, then perform an action
    if last_message.tool_calls:
        return "tool_node"

    # Otherwise, we stop (reply to the user)
    return END

# Build workflow
agent_builder = StateGraph(MessagesState)

# Add nodes
agent_builder.add_node("llm_call", llm_call)
agent_builder.add_node("tool_node", tool_node)

# Add edges to connect nodes
agent_builder.add_edge(START, "llm_call")
agent_builder.add_conditional_edges(
    "llm_call",
    should_continue,
    ["tool_node", END]
)
agent_builder.add_edge("tool_node", "llm_call")

# Compile the agent with checkpointer and store
checkpointer = MemorySaver()
store = InMemoryStore()
agent = agent_builder.compile(checkpointer=checkpointer, store=store)

# Show the agent - ä¿å­˜ä¸ºæ–‡ä»¶
print("ç”Ÿæˆ Agent å·¥ä½œæµå›¾è¡¨...")
png_data = agent.get_graph(xray=True).draw_mermaid_png()
with open("agent_graph.png", "wb") as f:
    f.write(png_data)
print("âœ… å›¾è¡¨å·²ä¿å­˜åˆ°: agent_graph.png")
print("   ä½¿ç”¨å‘½ä»¤æŸ¥çœ‹: open agent_graph.png\n")

# Invoke - ä½¿ç”¨ stream æ¨¡å¼æŸ¥çœ‹æ¯ä¸€æ­¥çš„ state
from langchain.messages import HumanMessage

# å®šä¹‰ thread_id é…ç½®
config = {"configurable": {"thread_id": "math-session-1"}}

print("=" * 70)
print("æ¼”ç¤º Checkpointer + Thread ID åŠŸèƒ½")
print("=" * 70)

# ========== ç¬¬ä¸€è½®å¯¹è¯ ==========
print("\n" + "=" * 70)
print("ç¬¬ä¸€è½®å¯¹è¯: Add 3 and 4")
print("=" * 70)

messages = [HumanMessage(content="Add 3 and 4.")]

for event in agent.stream({"messages": messages}, config=config, stream_mode="values"):
    pass  # åªæ‰§è¡Œï¼Œä¸æ‰“å°æ¯ä¸€æ­¥

# è·å–æœ€ç»ˆç»“æœ
final_state = agent.get_state(config)
last_message = final_state.values["messages"][-1]
print(f"\nå›ç­”: {last_message.content}")
print(f"å½“å‰æ¶ˆæ¯æ•°é‡: {len(final_state.values['messages'])}")

# ========== ç¬¬äºŒè½®å¯¹è¯ ==========
print("\n" + "=" * 70)
print("ç¬¬äºŒè½®å¯¹è¯: Now multiply that result by 2")
print("(Agent åº”è¯¥è®°å¾—ä¸Šä¸€è½®çš„ç»“æœæ˜¯ 7)")
print("=" * 70)

messages = [HumanMessage(content="Now multiply that result by 2.")]

for event in agent.stream({"messages": messages}, config=config, stream_mode="values"):
    pass

final_state = agent.get_state(config)
last_message = final_state.values["messages"][-1]
print(f"\nå›ç­”: {last_message.content}")
print(f"å½“å‰æ¶ˆæ¯æ•°é‡: {len(final_state.values['messages'])}")

# ========== ç¬¬ä¸‰è½®å¯¹è¯ ==========
print("\n" + "=" * 70)
print("ç¬¬ä¸‰è½®å¯¹è¯: Divide that by 7")
print("(Agent åº”è¯¥è®°å¾—ä¸Šä¸€è½®çš„ç»“æœæ˜¯ 14)")
print("=" * 70)

messages = [HumanMessage(content="Divide that by 7.")]

for event in agent.stream({"messages": messages}, config=config, stream_mode="values"):
    pass

final_state = agent.get_state(config)
last_message = final_state.values["messages"][-1]
print(f"\nå›ç­”: {last_message.content}")
print(f"å½“å‰æ¶ˆæ¯æ•°é‡: {len(final_state.values['messages'])}")

# ========== æŸ¥çœ‹å®Œæ•´å¯¹è¯å†å² ==========
print("\n" + "=" * 70)
print("å®Œæ•´å¯¹è¯å†å² (å­˜å‚¨åœ¨ checkpointer ä¸­)")
print("=" * 70)

all_messages = final_state.values["messages"]
for i, msg in enumerate(all_messages, 1):
    msg_type = msg.__class__.__name__
    if hasattr(msg, 'content') and msg.content:
        content = msg.content[:80] + "..." if len(str(msg.content)) > 80 else msg.content
        print(f"{i}. [{msg_type}] {content}")
    elif hasattr(msg, 'tool_calls') and msg.tool_calls:
        print(f"{i}. [{msg_type}] Tool calls: {[tc['name'] for tc in msg.tool_calls]}")

print(f"\nâœ… æ€»å…± {len(all_messages)} æ¡æ¶ˆæ¯")
print(f"âœ… Thread ID: {config['configurable']['thread_id']}")

# ========== æ‰“å° final_state çš„å®Œæ•´ç»“æ„ ==========
print("\n" + "=" * 70)
print("final_state çš„å®Œæ•´ç»“æ„")
print("=" * 70)

print(f"\nfinal_state ç±»å‹: {type(final_state)}")
print(f"final_state å±æ€§: {dir(final_state)}")

print("\n--- final_state.values ---")
print(f"ç±»å‹: {type(final_state.values)}")
print(f"é”®: {final_state.values.keys()}")
print(f"messages æ•°é‡: {len(final_state.values['messages'])}")
print(f"llm_calls: {final_state.values.get('llm_calls', 'N/A')}")

print("\n--- final_state.next ---")
print(f"ä¸‹ä¸€ä¸ªèŠ‚ç‚¹: {final_state.next}")

print("\n--- final_state.config ---")
print(f"é…ç½®: {final_state.config}")

print("\n--- final_state.metadata ---")
print(f"å…ƒæ•°æ®: {final_state.metadata}")

print("\n--- final_state.created_at ---")
print(f"åˆ›å»ºæ—¶é—´: {final_state.created_at}")

print("\n--- final_state.parent_config ---")
print(f"çˆ¶é…ç½®: {final_state.parent_config}")

# ========== æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤º ==========
print("\n" + "=" * 70)
print("ğŸ• æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤º")
print("=" * 70)

# è·å–æ‰€æœ‰å†å²çŠ¶æ€å¿«ç…§
print("\nğŸ“œ è·å–å®Œæ•´çš„çŠ¶æ€å†å²...")
history = list(agent.get_state_history(config))

print(f"\nå…±æœ‰ {len(history)} ä¸ªå†å²å¿«ç…§:")
print("-" * 70)

# å…ˆæ‰“å°å‡ ä¸ªä¸åŒçš„ metadata ç¤ºä¾‹
print("\nğŸ“‹ metadata çš„å®Œæ•´ç»“æ„:")
print("-" * 70)

# é€‰æ‹©å‡ ä¸ªæœ‰ä»£è¡¨æ€§çš„çŠ¶æ€
sample_indices = [0, 4, 9, 14] if len(history) > 14 else [0, len(history)//2, -1]
for idx in sample_indices:
    if idx < len(history):
        state = history[idx]
        print(f"\n  å¿«ç…§ [{idx}] (Step {state.metadata.get('step')}):")
        for key, value in state.metadata.items():
            print(f"    {key}: {value}")

print("\n" + "-" * 70)
print("\nğŸ“Š metadata å­—æ®µè¯´æ˜:")
print("  â€¢ source: çŠ¶æ€æ¥æº ('loop'=èŠ‚ç‚¹æ‰§è¡Œ, 'input'=ç”¨æˆ·è¾“å…¥)")
print("  â€¢ step: æ‰§è¡Œæ­¥éª¤å· (-1 æ˜¯åˆå§‹çŠ¶æ€)")
print("  â€¢ parents: çˆ¶çŠ¶æ€ä¿¡æ¯ï¼ˆç”¨äºåˆ†æ”¯ï¼‰")
print("  â€¢ writes: è¯¥æ­¥éª¤å†™å…¥çš„æ•°æ®ï¼ˆèŠ‚ç‚¹å â†’ å†™å…¥å†…å®¹ï¼‰")
print("-" * 70)

for i, state in enumerate(history):
    step = state.metadata.get('step', 'N/A')
    source = state.metadata.get('source', 'N/A')
    writes = state.metadata.get('writes', {})
    msg_count = len(state.values.get('messages', []))

    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„æ‘˜è¦
    if state.values.get('messages'):
        last_msg = state.values['messages'][-1]
        msg_type = last_msg.__class__.__name__
        if hasattr(last_msg, 'content') and last_msg.content:
            content = str(last_msg.content)[:25] + "..." if len(str(last_msg.content)) > 25 else last_msg.content
        elif hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
            content = f"Tool: {last_msg.tool_calls[0]['name']}"
        else:
            content = "..."
    else:
        msg_type = "Empty"
        content = "åˆå§‹çŠ¶æ€"

    # æ˜¾ç¤º writes ä¸­çš„èŠ‚ç‚¹å
    write_nodes = list(writes.keys()) if writes else []

    print(f"  [{i:2}] Step {step:2} | src: {source:5} | writes: {write_nodes} | {msg_count} msgs | {content}")

# æ—¶é—´æ—…è¡Œï¼šå›åˆ°æŸä¸ªå†å²çŠ¶æ€
print("\n" + "-" * 70)
print("ğŸ”™ æ—¶é—´æ—…è¡Œï¼šå›åˆ°ç¬¬ 4 æ­¥ï¼ˆç¬¬ä¸€æ¬¡è®¡ç®—å®Œæˆåï¼‰")
print("-" * 70)

# æ‰¾åˆ° step 4 çš„çŠ¶æ€
target_state = None
for state in history:
    if state.metadata.get('step') == 4:
        target_state = state
        break

if target_state:
    print(f"\nå›åˆ°çš„çŠ¶æ€:")
    print(f"  Step: {target_state.metadata.get('step')}")
    print(f"  æ¶ˆæ¯æ•°: {len(target_state.values['messages'])}")
    print(f"  Checkpoint ID: {target_state.config['configurable']['checkpoint_id']}")

    # æ˜¾ç¤ºè¯¥çŠ¶æ€çš„æ¶ˆæ¯
    print(f"\nè¯¥çŠ¶æ€ä¸‹çš„æ¶ˆæ¯:")
    for i, msg in enumerate(target_state.values['messages'], 1):
        msg_type = msg.__class__.__name__
        if hasattr(msg, 'content') and msg.content:
            print(f"    {i}. [{msg_type}] {msg.content}")
        elif hasattr(msg, 'tool_calls') and msg.tool_calls:
            print(f"    {i}. [{msg_type}] Tool: {msg.tool_calls[0]['name']}")

    # ä»è¿™ä¸ªå†å²çŠ¶æ€ç»§ç»­æ‰§è¡Œæ–°çš„æ“ä½œ
    print("\n" + "-" * 70)
    print("â© ä»å†å²çŠ¶æ€ç»§ç»­ï¼šMultiply the result by 10")
    print("   (ä» 7 ä¹˜ä»¥ 10ï¼Œè€Œä¸æ˜¯ä»æœ€ç»ˆçš„ 2)")
    print("-" * 70)

    # ä½¿ç”¨å†å²çŠ¶æ€çš„ config ç»§ç»­æ‰§è¡Œ
    history_config = target_state.config

    new_messages = [HumanMessage(content="Multiply the result by 10.")]

    # ä¿å­˜æœ€åä¸€ä¸ª event
    last_event = None
    for event in agent.stream({"messages": new_messages}, config=history_config, stream_mode="values"):
        last_event = event

    # ä» stream çš„æœ€åä¸€ä¸ª event è·å–ç»“æœ
    if last_event:
        last_message = last_event["messages"][-1]
        print(f"\nå›ç­”: {last_message.content}")
        print(f"æ¶ˆæ¯æ•°: {len(last_event['messages'])}")
    else:
        print("æ‰§è¡Œå¤±è´¥")

    # éªŒè¯ï¼šåº”è¯¥æ˜¯ 7 * 10 = 70ï¼Œè€Œä¸æ˜¯ 2 * 10 = 20
    print("\nâœ… æ—¶é—´æ—…è¡ŒæˆåŠŸï¼")
    print("   æˆ‘ä»¬å›åˆ°äº†ç¬¬ä¸€æ¬¡è®¡ç®—ï¼ˆ3+4=7ï¼‰åçš„çŠ¶æ€")
    print("   ç„¶åä»é‚£é‡Œç»§ç»­ï¼Œè®¡ç®— 7*10=70")
    print("   è€Œä¸æ˜¯ä»æœ€ç»ˆçŠ¶æ€ï¼ˆ14/7=2ï¼‰ç»§ç»­ï¼Œé‚£æ ·ä¼šæ˜¯ 2*10=20")

else:
    print("æœªæ‰¾åˆ°ç›®æ ‡çŠ¶æ€")

# ========== Store åŠŸèƒ½æ¼”ç¤ºï¼šè·¨çº¿ç¨‹å…±äº«ä¿¡æ¯ ==========
print("\n" + "=" * 70)
print("ğŸª Store åŠŸèƒ½æ¼”ç¤ºï¼šè·¨çº¿ç¨‹å…±äº«ä¿¡æ¯")
print("=" * 70)

print("""
Checkpointer vs Store:
  â€¢ Checkpointer: çº¿ç¨‹å†…çŠ¶æ€ä¿å­˜ï¼ˆthread_id éš”ç¦»ï¼‰
  â€¢ Store: è·¨çº¿ç¨‹æ•°æ®å…±äº«ï¼ˆå…¨å±€å­˜å‚¨ï¼‰
""")

# æ¼”ç¤º Store çš„åŸºæœ¬æ“ä½œ
print("-" * 70)
print("1ï¸âƒ£  Store åŸºæœ¬æ“ä½œ")
print("-" * 70)

# å­˜å‚¨ç”¨æˆ·åå¥½ï¼ˆå¯ä»¥è·¨çº¿ç¨‹è®¿é—®ï¼‰
store.put(
    namespace=("users", "user_123"),  # å‘½åç©ºé—´
    key="preferences",                 # é”®
    value={                            # å€¼
        "language": "ä¸­æ–‡",
        "favorite_operation": "multiply",
        "precision": 2
    }
)
print("\nâœ… å­˜å‚¨ç”¨æˆ·åå¥½:")
print('   store.put(("users", "user_123"), "preferences", {...})')

# å­˜å‚¨è®¡ç®—å†å²
store.put(
    namespace=("history", "user_123"),
    key="last_results",
    value={
        "results": [7, 14, 2, 70],
        "operations": ["add", "multiply", "divide", "multiply"]
    }
)
print("\nâœ… å­˜å‚¨è®¡ç®—å†å²:")
print('   store.put(("history", "user_123"), "last_results", {...})')

# è¯»å–æ•°æ®
print("\n" + "-" * 70)
print("2ï¸âƒ£  è¯»å– Store æ•°æ®")
print("-" * 70)

# è·å–ç”¨æˆ·åå¥½
prefs = store.get(namespace=("users", "user_123"), key="preferences")
print(f"\nè·å–ç”¨æˆ·åå¥½:")
print(f"   store.get(('users', 'user_123'), 'preferences')")
print(f"   ç»“æœ: {prefs.value if prefs else 'None'}")

# è·å–è®¡ç®—å†å²
history_data = store.get(namespace=("history", "user_123"), key="last_results")
print(f"\nè·å–è®¡ç®—å†å²:")
print(f"   store.get(('history', 'user_123'), 'last_results')")
print(f"   ç»“æœ: {history_data.value if history_data else 'None'}")

# æœç´¢æ•°æ®
print("\n" + "-" * 70)
print("3ï¸âƒ£  æœç´¢ Store æ•°æ®")
print("-" * 70)

# æœç´¢æŸä¸ªå‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰æ•°æ®
user_data = list(store.search(("users",)))
print(f"\næœç´¢ users å‘½åç©ºé—´:")
print(f"   store.search(('users',))")
print(f"   æ‰¾åˆ° {len(user_data)} æ¡æ•°æ®")

all_data = list(store.search(()))
print(f"\næœç´¢æ‰€æœ‰æ•°æ®:")
print(f"   store.search(())")
print(f"   æ‰¾åˆ° {len(all_data)} æ¡æ•°æ®")

for item in all_data:
    print(f"   - namespace: {item.namespace}, key: {item.key}")

# æ¼”ç¤ºè·¨çº¿ç¨‹å…±äº«
print("\n" + "-" * 70)
print("4ï¸âƒ£  è·¨çº¿ç¨‹å…±äº«æ¼”ç¤º")
print("-" * 70)

# çº¿ç¨‹ 1 å­˜å‚¨æ•°æ®
config_thread1 = {"configurable": {"thread_id": "thread-1"}}
store.put(
    namespace=("shared", "global"),
    key="important_number",
    value={"number": 42, "set_by": "thread-1"}
)
print("\nçº¿ç¨‹ 1 å­˜å‚¨å…±äº«æ•°æ®:")
print('   store.put(("shared", "global"), "important_number", {number: 42})')

# çº¿ç¨‹ 2 è¯»å–æ•°æ®ï¼ˆä¸åŒçš„ thread_idï¼Œä½†å¯ä»¥è®¿é—®åŒä¸€ä¸ª storeï¼‰
config_thread2 = {"configurable": {"thread_id": "thread-2"}}
shared_data = store.get(namespace=("shared", "global"), key="important_number")
print("\nçº¿ç¨‹ 2 è¯»å–å…±äº«æ•°æ®:")
print(f'   store.get(("shared", "global"), "important_number")')
print(f"   ç»“æœ: {shared_data.value if shared_data else 'None'}")

print("\n" + "-" * 70)
print("5ï¸âƒ£  Store vs Checkpointer å¯¹æ¯”")
print("-" * 70)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç‰¹æ€§          â”‚ Checkpointer           â”‚ Store                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ•°æ®éš”ç¦»      â”‚ æŒ‰ thread_id éš”ç¦»      â”‚ å…¨å±€å…±äº«              â”‚
â”‚ ç”¨é€”          â”‚ å¯¹è¯çŠ¶æ€ã€æ‰§è¡Œå†å²     â”‚ ç”¨æˆ·åå¥½ã€é•¿æœŸè®°å¿†    â”‚
â”‚ ç”Ÿå‘½å‘¨æœŸ      â”‚ éšçº¿ç¨‹                 â”‚ æŒä¹…åŒ–                â”‚
â”‚ è®¿é—®æ–¹å¼      â”‚ agent.get_state()      â”‚ store.get/put/search  â”‚
â”‚ å…¸å‹æ•°æ®      â”‚ messages, tool_calls   â”‚ preferences, profiles â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# æ›´æ–°æ•°æ®
print("-" * 70)
print("6ï¸âƒ£  æ›´æ–°å’Œåˆ é™¤æ•°æ®")
print("-" * 70)

# æ›´æ–°
store.put(
    namespace=("users", "user_123"),
    key="preferences",
    value={
        "language": "English",  # æ›´æ–°
        "favorite_operation": "divide",  # æ›´æ–°
        "precision": 4  # æ›´æ–°
    }
)
updated_prefs = store.get(namespace=("users", "user_123"), key="preferences")
print("\næ›´æ–°ç”¨æˆ·åå¥½:")
print(f"   æ–°å€¼: {updated_prefs.value if updated_prefs else 'None'}")

# åˆ é™¤
store.delete(namespace=("shared", "global"), key="important_number")
deleted_data = store.get(namespace=("shared", "global"), key="important_number")
print("\nåˆ é™¤å…±äº«æ•°æ®:")
print(f"   store.delete(('shared', 'global'), 'important_number')")
print(f"   éªŒè¯: {deleted_data}")

print("\n" + "=" * 70)
print("âœ… Store åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
print("=" * 70)
print("""
Store çš„å…¸å‹åº”ç”¨åœºæ™¯:
  â€¢ ç”¨æˆ·é…ç½®å’Œåå¥½ï¼ˆè·¨ä¼šè¯ä¿æŒï¼‰
  â€¢ é•¿æœŸè®°å¿†ï¼ˆè·¨çº¿ç¨‹å…±äº«ï¼‰
  â€¢ å…¨å±€çŠ¶æ€ï¼ˆå¦‚ç³»ç»Ÿé…ç½®ï¼‰
  â€¢ ç¼“å­˜æ•°æ®ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
""")

# ========== äººæœºäº¤äº’ï¼ˆHuman-in-the-loopï¼‰æ¼”ç¤º ==========
print("\n" + "=" * 70)
print("ğŸ¤ äººæœºäº¤äº’ï¼ˆHuman-in-the-loopï¼‰æ¼”ç¤º")
print("=" * 70)

print("""
äººæœºäº¤äº’å…è®¸åœ¨å·¥ä½œæµæ‰§è¡Œè¿‡ç¨‹ä¸­ï¼š
  â€¢ æš‚åœæ‰§è¡Œç­‰å¾…äººç±»ç¡®è®¤
  â€¢ äººç±»å®¡æ ¸åç»§ç»­æˆ–ä¿®æ”¹
  â€¢ å®ç°å®¡æ‰¹æµç¨‹
""")

# åˆ›å»ºä¸€ä¸ªå¸¦äººæœºäº¤äº’çš„ç®€å•å·¥ä½œæµ
class ApprovalState(TypedDict):
    task: str
    result: str
    approved: bool

def generate_result(state: ApprovalState):
    """ç”Ÿæˆç»“æœ"""
    task = state["task"]
    # æ¨¡æ‹Ÿç”Ÿæˆç»“æœ
    result = f"è®¡ç®—ç»“æœ: {task} = 42"
    print(f"\nğŸ¤– ç”Ÿæˆç»“æœ: {result}")
    return {"result": result}

def human_approval(state: ApprovalState):
    """äººæœºäº¤äº’èŠ‚ç‚¹ - ç­‰å¾…äººç±»å®¡æ‰¹"""
    print(f"\nâ¸ï¸  ç­‰å¾…äººç±»å®¡æ‰¹...")
    print(f"   å¾…å®¡æ‰¹å†…å®¹: {state['result']}")

    # ä½¿ç”¨ interrupt() æš‚åœæ‰§è¡Œ
    # äººç±»å¯ä»¥æŸ¥çœ‹ç»“æœå¹¶å†³å®šæ˜¯å¦æ‰¹å‡†
    approval = interrupt({
        "question": "è¯·å®¡æ‰¹ä»¥ä¸‹ç»“æœ",
        "result": state["result"],
        "options": ["approve", "reject", "modify"]
    })

    print(f"\nâœ… æ”¶åˆ°äººç±»åé¦ˆ: {approval}")

    if approval == "approve":
        return {"approved": True}
    elif approval == "reject":
        return {"approved": False}
    else:
        # å¦‚æœæ˜¯ä¿®æ”¹ï¼Œapproval å°±æ˜¯ä¿®æ”¹åçš„å€¼
        return {"result": approval, "approved": True}

def finalize(state: ApprovalState):
    """æœ€ç»ˆå¤„ç†"""
    if state["approved"]:
        print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼æœ€ç»ˆç»“æœ: {state['result']}")
    else:
        print(f"\nâŒ ä»»åŠ¡è¢«æ‹’ç»")
    return {}

# æ„å»ºäººæœºäº¤äº’å·¥ä½œæµ
approval_builder = StateGraph(ApprovalState)
approval_builder.add_node("generate", generate_result)
approval_builder.add_node("human_approval", human_approval)
approval_builder.add_node("finalize", finalize)

approval_builder.add_edge(START, "generate")
approval_builder.add_edge("generate", "human_approval")
approval_builder.add_edge("human_approval", "finalize")
approval_builder.add_edge("finalize", END)

# ç¼–è¯‘æ—¶éœ€è¦ checkpointerï¼ˆç”¨äºä¿å­˜ä¸­æ–­çŠ¶æ€ï¼‰
approval_checkpointer = MemorySaver()
approval_agent = approval_builder.compile(checkpointer=approval_checkpointer)

# ä¿å­˜å·¥ä½œæµå›¾
print("\nç”Ÿæˆäººæœºäº¤äº’å·¥ä½œæµå›¾...")
png_data = approval_agent.get_graph().draw_mermaid_png()
with open("approval_workflow_graph.png", "wb") as f:
    f.write(png_data)
print("âœ… å›¾è¡¨å·²ä¿å­˜åˆ°: approval_workflow_graph.png")

# æ¼”ç¤ºæ‰§è¡Œ
print("\n" + "-" * 70)
print("æ‰§è¡Œäººæœºäº¤äº’å·¥ä½œæµ")
print("-" * 70)

approval_config = {"configurable": {"thread_id": "approval-demo-1"}}

# ç¬¬ä¸€æ¬¡æ‰§è¡Œ - ä¼šåœ¨ human_approval èŠ‚ç‚¹æš‚åœ
print("\nğŸ“ ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆä¼šæš‚åœç­‰å¾…å®¡æ‰¹ï¼‰...")
for event in approval_agent.stream(
    {"task": "2 + 2", "result": "", "approved": False},
    config=approval_config,
    stream_mode="values"
):
    pass

# æ£€æŸ¥çŠ¶æ€
state = approval_agent.get_state(approval_config)
print(f"\nå½“å‰çŠ¶æ€:")
print(f"   next: {state.next}")  # ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹

# æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–­
if state.next:
    print(f"   â¸ï¸  å·¥ä½œæµå·²æš‚åœï¼Œç­‰å¾…äººç±»è¾“å…¥")

    # è·å–ä¸­æ–­ä¿¡æ¯
    interrupt_info = None
    if hasattr(state, 'tasks') and state.tasks:
        for task in state.tasks:
            if hasattr(task, 'interrupts') and task.interrupts:
                interrupt_info = task.interrupts[0].value
                print(f"\n   ğŸ“‹ ä¸­æ–­ä¿¡æ¯:")
                print(f"      é—®é¢˜: {interrupt_info.get('question')}")
                print(f"      ç»“æœ: {interrupt_info.get('result')}")
                print(f"      é€‰é¡¹: {interrupt_info.get('options')}")

    # çœŸæ­£çš„äººæœºäº¤äº’ - ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼
    print("\n" + "-" * 70)
    print("ğŸ–ï¸  è¯·è¾“å…¥æ‚¨çš„å†³å®š:")
    print("   - è¾“å…¥ 'approve' æ‰¹å‡†")
    print("   - è¾“å…¥ 'reject' æ‹’ç»")
    print("   - è¾“å…¥å…¶ä»–å†…å®¹ä½œä¸ºä¿®æ”¹åçš„ç»“æœ")
    print("-" * 70)

    # ä½¿ç”¨ input() è·å–çœŸå®ç”¨æˆ·è¾“å…¥
    user_input = input("\nğŸ‘‰ æ‚¨çš„è¾“å…¥: ").strip()

    if not user_input:
        user_input = "approve"  # é»˜è®¤æ‰¹å‡†
        print(f"   (æœªè¾“å…¥ï¼Œé»˜è®¤: {user_input})")

    print(f"\nğŸ“¨ å‘é€ç”¨æˆ·è¾“å…¥: {user_input}")

    # ä½¿ç”¨ Command.resume() æ¢å¤æ‰§è¡Œå¹¶ä¼ é€’çœŸå®çš„äººç±»è¾“å…¥
    for event in approval_agent.stream(
        Command(resume=user_input),  # çœŸå®çš„äººç±»è¾“å…¥ï¼
        config=approval_config,
        stream_mode="values"
    ):
        pass

    # æ£€æŸ¥æœ€ç»ˆçŠ¶æ€
    final_state = approval_agent.get_state(approval_config)
    print(f"\næœ€ç»ˆçŠ¶æ€:")
    print(f"   result: {final_state.values.get('result')}")
    print(f"   approved: {final_state.values.get('approved')}")

print("\n" + "-" * 70)
print("äººæœºäº¤äº’çš„å…³é”®ä»£ç ")
print("-" * 70)

print("""
1ï¸âƒ£  åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨ interrupt() æš‚åœ:

    from langgraph.types import interrupt

    def human_approval(state):
        # æš‚åœå¹¶ç­‰å¾…äººç±»è¾“å…¥
        approval = interrupt({
            "question": "è¯·å®¡æ‰¹",
            "result": state["result"]
        })
        return {"approved": approval == "approve"}

2ï¸âƒ£  æ¢å¤æ‰§è¡Œå¹¶ä¼ é€’äººç±»è¾“å…¥:

    from langgraph.types import Command

    # ä½¿ç”¨ Command.resume() æ¢å¤
    agent.stream(
        Command(resume="approve"),  # äººç±»çš„è¾“å…¥
        config=config
    )

3ï¸âƒ£  æ£€æŸ¥ä¸­æ–­çŠ¶æ€:

    state = agent.get_state(config)
    if state.next:
        print("å·¥ä½œæµå·²æš‚åœ")

4ï¸âƒ£  å…¸å‹åº”ç”¨åœºæ™¯:

    â€¢ æ•æ„Ÿæ“ä½œå®¡æ‰¹ï¼ˆåˆ é™¤ã€æ”¯ä»˜ç­‰ï¼‰
    â€¢ AI ç”Ÿæˆå†…å®¹å®¡æ ¸
    â€¢ å¤šæ­¥éª¤ç¡®è®¤æµç¨‹
    â€¢ éœ€è¦äººç±»åˆ¤æ–­çš„å†³ç­–ç‚¹
""")

print("\n" + "=" * 70)
print("âœ… äººæœºäº¤äº’æ¼”ç¤ºå®Œæˆï¼")
print("=" * 70)