from typing_extensions import TypedDict, Literal
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI

# é…ç½® LLM
openai_api_key = "sk-nRyX1HmENCf4QEk5V0yWZKrQkIKKnEfXloy9lSOe3Jjl9AJH"
base_url = "https://api.poixe.com/v1"

llm = ChatOpenAI(
    openai_api_key=openai_api_key,
    base_url=base_url
)

# Graph state
class State(TypedDict):
    joke: str
    topic: str
    feedback: str
    funny_or_not: str


# Schema for structured output to use in evaluation
class Feedback(BaseModel):
    grade: Literal["funny", "not funny"] = Field(
        description="Decide if the joke is funny or not.",
    )
    feedback: str = Field(
        description="If the joke is not funny, provide feedback on how to improve it.",
    )


# Augment the LLM with schema for structured output
evaluator = llm.with_structured_output(Feedback)


# è®¡æ•°å™¨
iteration_count = 0

# Nodes
def llm_call_generator(state: State):
    """LLM generates a joke"""
    global iteration_count
    iteration_count += 1

    print(f"\nğŸ­ Generator - ç¬¬ {iteration_count} æ¬¡å°è¯•")

    if state.get("feedback"):
        print(f"   ğŸ“ æ”¶åˆ°åé¦ˆ: {state['feedback']}")
        msg = llm.invoke(
            f"Write a joke about {state['topic']} but take into account the feedback: {state['feedback']}"
        )
    else:
        print(f"   ğŸ“ é¦–æ¬¡ç”Ÿæˆï¼Œä¸»é¢˜: {state['topic']}")
        msg = llm.invoke(f"Write a joke about {state['topic']}")

    print(f"   ğŸ¤ ç”Ÿæˆçš„ç¬‘è¯: {msg.content[:100]}...")
    return {"joke": msg.content}


def llm_call_evaluator(state: State):
    """LLM evaluates the joke"""

    print(f"\nğŸ” Evaluator - è¯„ä¼°ç¬‘è¯")

    # è¯„ä¼°å™¨çŸ¥é“ä¸€äº›è€å¥—ç¬‘è¯
    grade = evaluator.invoke(
        f"""Grade this joke. Mark as 'funny' if it has some creativity or clever wordplay.

        IMPORTANT: The following jokes are overused and should ALWAYS be marked as 'not funny':
        - "Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!"
        - Any variation of cat + computer + mouse joke
        - "Why did the chicken cross the road?"

        If you see these old jokes, provide feedback suggesting a completely different topic or angle.

        Joke: {state['joke']}"""
    )

    print(f"   ğŸ“Š è¯„åˆ†: {grade.grade}")
    if grade.grade == "not funny":
        print(f"   ğŸ’¡ æ”¹è¿›å»ºè®®: {grade.feedback}")

    return {"funny_or_not": grade.grade, "feedback": grade.feedback}


# Conditional edge function to route back to joke generator or end based upon feedback from the evaluator
def route_joke(state: State):
    """Route back to joke generator or end based upon feedback from the evaluator"""

    if state["funny_or_not"] == "funny":
        return "Accepted"
    elif state["funny_or_not"] == "not funny":
        return "Rejected + Feedback"


# Build workflow
optimizer_builder = StateGraph(State)

# Add the nodes
optimizer_builder.add_node("llm_call_generator", llm_call_generator)
optimizer_builder.add_node("llm_call_evaluator", llm_call_evaluator)

# Add edges to connect nodes
optimizer_builder.add_edge(START, "llm_call_generator")
optimizer_builder.add_edge("llm_call_generator", "llm_call_evaluator")
optimizer_builder.add_conditional_edges(
    "llm_call_evaluator",
    route_joke,
    {  # Name returned by route_joke : Name of next node to visit
        "Accepted": END,
        "Rejected + Feedback": "llm_call_generator",
    },
)

# Compile the workflow
optimizer_workflow = optimizer_builder.compile()

# Show the workflow - ä¿å­˜ä¸ºæ–‡ä»¶
print("ç”Ÿæˆè¯„ä¼°å™¨-ä¼˜åŒ–å™¨å·¥ä½œæµå›¾è¡¨...")
png_data = optimizer_workflow.get_graph().draw_mermaid_png()
with open("evaluator_optimizer_graph.png", "wb") as f:
    f.write(png_data)
print("âœ… å›¾è¡¨å·²ä¿å­˜åˆ°: evaluator_optimizer_graph.png")
print("   ä½¿ç”¨å‘½ä»¤æŸ¥çœ‹: open evaluator_optimizer_graph.png\n")

# Invoke
print("=" * 70)
print("å¼€å§‹ç”Ÿæˆç¬‘è¯ (ä½¿ç”¨ä¸¥æ ¼è¯„ä¼°æ¨¡å¼)")
print("=" * 70)

# å¢åŠ é€’å½’é™åˆ¶ï¼Œå…è®¸æ›´å¤šæ¬¡å¾ªç¯
state = optimizer_workflow.invoke(
    {"topic": "Cats"},
    {"recursion_limit": 50}  # é»˜è®¤æ˜¯ 25
)

print("\n" + "=" * 70)
print(f"âœ… å®Œæˆï¼å…±ç»è¿‡ {iteration_count} æ¬¡å¾ªç¯")
print("=" * 70)
print("\næœ€ç»ˆç¬‘è¯:")
print(state["joke"])
print(f"\nè¯„ä¼°ç»“æœ: {state['funny_or_not']}")